{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c58701",
   "metadata": {},
   "source": [
    "# Data Splitting and Hyperparameter Tuning in Machine Learning\n",
    "\n",
    "Proper data splitting is essential before performing any model evaluation or hyperparameter tuning. This notebook demonstrates how to split data, tune hyperparameters using `GridSearchCV`, and evaluate model performance correctly.\n",
    "\n",
    "> For information on how to handle data imbalance, refer to:  \n",
    "> [data_balancing.ipynb](./data_balancing.ipynb)\n",
    "\n",
    "\n",
    "### Order:\n",
    "\n",
    "1. Split full dataset into training and test sets\n",
    "2. Use only the training set for cross-validation & tuning\n",
    "3. Use the test set strictly for final performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07367120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5976a0",
   "metadata": {},
   "source": [
    "- **train_test_split**: A function from `sklearn.model_selection` used to split the dataset into training and test subsets.\n",
    "- **X**: The input features (independent variables).\n",
    "\n",
    "- **y**: The target labels (dependent variable).\n",
    "\n",
    "- **test_size=0.2**: Specifies that 20% of the data will be used as the test set, and 80% as the training set.\n",
    "\n",
    "- **stratify=y**: Ensures that the class distribution of the target variable `y` is maintained proportionally in both training and test sets (important for classification).\n",
    "\n",
    "- **random_state=42**: Sets the random seed for reproducibility, so the split is the same every time this code is run.\n",
    "\n",
    "This split prepares the data for training models on the training set and evaluating performance on the unseen test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d1718",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Using GridSearchCV\n",
    "\n",
    "Once the data is split, we apply `GridSearchCV` on the **training set only**. Internally, it uses cross-validation to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc50015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {'C': [0.1, 1, 10]}\n",
    "\n",
    "# Set up GridSearchCV on training set\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Fit only on training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb23dfb",
   "metadata": {},
   "source": [
    "**Regularization** is a technique used to prevent a model from overfitting the training data.\n",
    "The parameter **C** is the inverse of the regularization strength.\n",
    "\n",
    "- A smaller **C** means stronger regularization, which reduces model complexity.  \n",
    "- A larger **C** means weaker regularization, allowing the model to fit the data more closely.\n",
    "\n",
    "`GridSearchCV` tries different values of **C** to find the best balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73953c",
   "metadata": {},
   "source": [
    "## Final Evaluation on Test Set\n",
    "\n",
    "Evaluate the best model using the **test set**, which has not been seen during training or tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43a43f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on the test set\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Accuracy score\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea1647e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Step             | Purpose                                    |\n",
    "|------------------|--------------------------------------------|\n",
    "| **Train/Test Split** | Isolate unseen data for final evaluation   |\n",
    "| **GridSearchCV**     | Tune hyperparameters using cross-validation |\n",
    "| **Test Evaluation**  | Measure generalisation performance (no tuning) |\n",
    "\n",
    "**Never use the test set during model tuning. Doing so results in data leakage and unreliable performance estimates.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
