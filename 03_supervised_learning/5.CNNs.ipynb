{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4fa596",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs) - Basics\n",
    "\n",
    "# 1. What is a CNN?\n",
    "\n",
    "A Convolutional Neural Network (CNN) is a type of deep learning model especially effective for image-related tasks.\n",
    "\n",
    "**Input:**  \n",
    "Labeled dataset of images `x` and target values `y`.  \n",
    "(Input data consists of images `x` with corresponding labels or target values `y`.)\n",
    "\n",
    "**Goal:**  \n",
    "Learn a mapping function `f(x; θ)` that minimizes prediction error using a loss function `L`.  \n",
    "(The goal is to find a function `f`, parameterized by `θ`, which maps input images `x` to outputs as close as possible to the true labels `y`. The model learns by minimizing the difference between predictions and true labels, measured by a loss function `L`.)\n",
    "\n",
    "**Training:**  \n",
    "Optimizes model parameters `θ` by minimizing the empirical loss:\n",
    "\n",
    "D = { (x₁, y₁), (x₂, y₂), ..., (x_N, y_N) }\n",
    "\n",
    "min_θ (1/N) * Σᵢ=1ⁿ L(f(xᵢ; θ), yᵢ)\n",
    "\n",
    "(During training, the model adjusts its parameters `θ` to minimize the average loss over the dataset, where `N` is the number of samples.)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Key Layers in a CNN\n",
    "\n",
    "- **Conv2D Layer**: Applies filters (kernels) to extract features.\n",
    "- **ReLU**: Applies non-linearity (activation function).\n",
    "- **MaxPooling**: Downsamples feature maps to reduce spatial size.\n",
    "- **Fully Connected Layer**: Final classifier that outputs prediction scores.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Simple CNN Architecture Example\n",
    "\n",
    "```text\n",
    "Input (e.g., 28x28 image)\n",
    "↓\n",
    "Conv2D → ReLU\n",
    "↓\n",
    "MaxPooling\n",
    "↓\n",
    "Conv2D → ReLU\n",
    "↓\n",
    "MaxPooling\n",
    "↓\n",
    "Flatten\n",
    "↓\n",
    "Fully Connected → Softmax\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    "## 4. Sample Use Case: MNIST Digit Classification\n",
    "cnn_basic.py for a runnable PyTorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36a1007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: filelock in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8255e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 210.2475\n",
      "Epoch 2, Loss: 59.3162\n",
      "Epoch 3, Loss: 41.2711\n",
      "Epoch 4, Loss: 31.2467\n",
      "Epoch 5, Loss: 24.5889\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a simple CNN\n",
    "class BasicCNN(nn.Module):\n",
    "    \"\"\"A simple Convolutional Neural Network for MNIST classification.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__() # Initialize the parent class\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1) # Input channels = 1 (grayscale), Output channels = 16\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # Input channels = 16, Output channels = 32\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 2x2 max pooling\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128) # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10) # Output layer for 10 classes (digits 0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Defines the forward pass of the CNN.\"\"\"\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [batch, 16, 14, 14]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [batch, 32, 7, 7]\n",
    "        x = x.view(-1, 32 * 7 * 7)            # flatten - vectorize the output\n",
    "        x = F.relu(self.fc1(x))               # [batch, 128]\n",
    "        x = self.fc2(x)                       # [batch, 10]\n",
    "        return x\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()]) # Convert images to PyTorch tensors\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform) # Training set\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True) # DataLoader for batching\n",
    "\n",
    "# Instantiate model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU if available\n",
    "model = BasicCNN().to(device) # Move model to device\n",
    "criterion = nn.CrossEntropyLoss() # Loss function for multi-class classification \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Optimizer for training\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # 5 epochs\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device) # Move data to device\n",
    "        \n",
    "        optimizer.zero_grad() # Zero the gradients\n",
    "        outputs = model(images) # Forward pass\n",
    "        loss = criterion(outputs, labels) # Compute loss \n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() # Update weights\n",
    "        \n",
    "        running_loss += loss.item() # Accumulate loss for this batch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35807a1",
   "metadata": {},
   "source": [
    "## 5. Math Concepts\n",
    "\n",
    "### Conv2D Output Size\n",
    "\n",
    "```\n",
    "H_out = floor((H_in + 2P - D(K - 1) - 1) / S + 1)\n",
    "```\n",
    " \n",
    "- **H_in**: Input height (or width) of the image or feature map  \n",
    "- **P (padding)**: Number of pixels added around the border of the input  \n",
    "- **D (dilation)**: Spacing between kernel elements, usually 1 (no dilation)  \n",
    "- **K (kernel size)**: Size of the convolutional filter (e.g., 3 means 3×3)  \n",
    "- **S (stride)**: Step size for moving the filter across the input  \n",
    "\n",
    "This formula calculates the size of the output after convolution.\n",
    "\n",
    "### ReLU\n",
    "\n",
    "```\n",
    "F.relu(x) = max(0, x)\n",
    "```\n",
    "\n",
    "- Outputs zero if input is less than or equal to zero, otherwise outputs the input.  \n",
    "- Adds non-linearity so the network can learn complex patterns.\n",
    "\n",
    "\n",
    "### CrossEntropyLoss\n",
    "\n",
    "```\n",
    "L(x, y) = -log(exp(x[y]) / sum_j exp(x[j]))\n",
    "```\n",
    "\n",
    "- **x**: Raw output scores (logits) from the model for each class  \n",
    "- **y**: True class label index  \n",
    "\n",
    "CrossEntropyLoss measures the difference between predicted probabilities and true labels.\n",
    "\n",
    "In PyTorch:\n",
    "\n",
    "```python\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(outputs, labels)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Hyperparameters\n",
    "\n",
    "- **Learning rate**  \n",
    "  Controls how much the model's weights are updated during training.  \n",
    "  - Typical values: `0.001`, `0.01`, `0.0001`  \n",
    "  - **If too large**: Training may become unstable or diverge (loss jumps around).  \n",
    "  - **If too small**: Training will be very slow and may get stuck in suboptimal solutions.\n",
    "\n",
    "- **Batch size**  \n",
    "  Number of training samples used to compute the gradient in one iteration.  \n",
    "  - Typical values: `32`, `64`, `128`  \n",
    "  - **Large batch size**: Faster training per epoch but may lead to worse generalization. Requires more memory.  \n",
    "  - **Small batch size**: Noisier gradient estimates, which can help escape local minima but slower training.\n",
    "\n",
    "- **Epochs**  \n",
    "  Number of full passes through the entire training dataset.  \n",
    "  - Typical values: `5`, `10`, `50`  \n",
    "  - **Too few epochs**: Underfitting (model doesn’t learn enough).  \n",
    "  - **Too many epochs**: Overfitting (model memorizes training data, poor on unseen data).\n",
    "\n",
    "- **Weight decay (L2 regularization)**  \n",
    "  Adds a penalty to large weights to reduce overfitting.  \n",
    "  - Typical values: `1e-5`, `1e-4`, `1e-3`  \n",
    "  - **Higher weight decay**: Stronger regularization, can prevent overfitting but may underfit.  \n",
    "  - **Lower weight decay**: Less regularization, may overfit.\n",
    "\n",
    "- **Dropout**  \n",
    "  Randomly disables neurons during training to prevent over-reliance on any one feature.  \n",
    "  - Typical dropout rates: `0.1` (10%), `0.3`, `0.5` (50%)  \n",
    "  - **Higher dropout**: Stronger regularization, may slow down learning.  \n",
    "  - **Lower dropout**: Less regularization, risk of overfitting.\n",
    "\n",
    "- **Data augmentation**  \n",
    "  Artificially increases dataset size by applying random transformations such as flipping, rotation, or cropping.  \n",
    "  - Helps model generalize better by seeing more varied examples.  \n",
    "  - Over-aggressive augmentation may create unrealistic samples that confuse the model.\n",
    "\n",
    "  \n",
    "\n",
    "---\n",
    "\n",
    "## 7. Other Activation Functions\n",
    "\n",
    "| Function    | Formula                         | Notes                         |\n",
    "|-------------|----------------------------------|-------------------------------|\n",
    "| Sigmoid     | `1 / (1 + exp(-x))`             | Can cause vanishing gradients |\n",
    "| Tanh        | `(e^x - e^-x)/(e^x + e^-x)`     | Zero-centered                 |\n",
    "| ReLU        | `max(0, x)`                     | Efficient, may die on 0       |\n",
    "| LeakyReLU   | `max(αx, x)`                    | Prevents dying ReLU           |\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Evaluation\n",
    "\n",
    "- **Accuracy**: correct predictions / total samples  \n",
    "- **Precision, Recall, F1-score**: useful for imbalanced datasets  \n",
    "- **Confusion Matrix**: shows true/false positives/negatives  \n",
    "\n",
    "---\n",
    "\n",
    "## 9. Transfer Learning (Optional)\n",
    "\n",
    "Use pretrained models like **ResNet**:\n",
    "\n",
    "```python\n",
    "from torchvision import models  \n",
    "model = models.resnet18(pretrained=True)  \n",
    "\n",
    "# Freeze all layers\n",
    "for param in model.parameters():  \n",
    "    param.requires_grad = False  \n",
    "\n",
    "# Replace the final fully connected layer\n",
    "model.fc = nn.Linear(512, 10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262eb6b4",
   "metadata": {},
   "source": [
    "## References and Further Reading\n",
    "\n",
    "- Andrew Ng, *Machine Learning*, Coursera (Stanford University)  \n",
    "  [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)\n",
    "\n",
    "- DeepLearning.AI, *Supervised Machine Learning: Regression and Classification* (Coursera)  \n",
    "  [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)\n",
    "\n",
    "- Kaggle, *Intro to Machine Learning Micro-course*  \n",
    "  [https://www.kaggle.com/learn/intro-to-machine-learning](https://www.kaggle.com/learn/intro-to-machine-learning)\n",
    "\n",
    "- scikit-learn Documentation, *Supervised Learning*  \n",
    "  [https://scikit-learn.org/stable/supervised_learning.html](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "\n",
    "- Stanford University, *CS231n: Convolutional Neural Networks for Visual Recognition*  \n",
    "  [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)\n",
    "\n",
    "- PyTorch, *Official Documentation*  \n",
    "  [https://pytorch.org](https://pytorch.org)\n",
    "\n",
    "- Yann LeCun, *The MNIST Database of Handwritten Digits*  \n",
    "  [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
