{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4fa596",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs) - Basics\n",
    "\n",
    "## 1. What is a CNN?\n",
    "\n",
    "A Convolutional Neural Network (CNN) is a type of deep learning model especially effective for image-related tasks.\n",
    "\n",
    "- **Input**: Labeled dataset of images `\\(\\boldsymbol{x}\\)` and target values `\\(y\\)`\n",
    "- **Goal**: Learn a mapping function `\\(f(\\boldsymbol{x}; \\theta)\\)` that minimises prediction error using a loss function `\\(\\mathcal{L}\\)`\n",
    "- **Training**: Optimises model parameters `\\(\\theta\\)` by minimising the empirical loss:\n",
    "\n",
    "D = { (x₁, y₁), (x₂, y₂), ..., (x_N, y_N) }\n",
    "\n",
    "min_θ (1/N) * Σᵢ=1ⁿ L(f(xᵢ; θ), yᵢ)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Key Layers in a CNN\n",
    "\n",
    "- **Conv2D Layer**: Applies filters (kernels) to extract features.\n",
    "- **ReLU**: Applies non-linearity (activation function).\n",
    "- **MaxPooling**: Downsamples feature maps to reduce spatial size.\n",
    "- **Fully Connected Layer**: Final classifier that outputs prediction scores.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Simple CNN Architecture Example\n",
    "\n",
    "```text\n",
    "Input (e.g., 28x28 image)\n",
    "↓\n",
    "Conv2D → ReLU\n",
    "↓\n",
    "MaxPooling\n",
    "↓\n",
    "Conv2D → ReLU\n",
    "↓\n",
    "MaxPooling\n",
    "↓\n",
    "Flatten\n",
    "↓\n",
    "Fully Connected → Softmax\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    "## 4. Sample Use Case: MNIST Digit Classification\n",
    "cnn_basic.py for a runnable PyTorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36a1007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: filelock in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\github_repo\\ml-foundations-notebook\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8255e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 210.2475\n",
      "Epoch 2, Loss: 59.3162\n",
      "Epoch 3, Loss: 41.2711\n",
      "Epoch 4, Loss: 31.2467\n",
      "Epoch 5, Loss: 24.5889\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a simple CNN\n",
    "class BasicCNN(nn.Module):\n",
    "    \"\"\"A simple Convolutional Neural Network for MNIST classification.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__() # Initialize the parent class\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1) # Input channels = 1 (grayscale), Output channels = 16\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # Input channels = 16, Output channels = 32\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 2x2 max pooling\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128) # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10) # Output layer for 10 classes (digits 0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Defines the forward pass of the CNN.\"\"\"\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [batch, 16, 14, 14]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [batch, 32, 7, 7]\n",
    "        x = x.view(-1, 32 * 7 * 7)            # flatten - vectorize the output\n",
    "        x = F.relu(self.fc1(x))               # [batch, 128]\n",
    "        x = self.fc2(x)                       # [batch, 10]\n",
    "        return x\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()]) # Convert images to PyTorch tensors\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform) # Training set\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True) # DataLoader for batching\n",
    "\n",
    "# Instantiate model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU if available\n",
    "model = BasicCNN().to(device) # Move model to device\n",
    "criterion = nn.CrossEntropyLoss() # Loss function for multi-class classification \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Optimizer for training\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # 5 epochs\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device) # Move data to device\n",
    "        \n",
    "        optimizer.zero_grad() # Zero the gradients\n",
    "        outputs = model(images) # Forward pass\n",
    "        loss = criterion(outputs, labels) # Compute loss \n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() # Update weights\n",
    "        \n",
    "        running_loss += loss.item() # Accumulate loss for this batch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35807a1",
   "metadata": {},
   "source": [
    "# 5. Explanation\n",
    "## 1. `nn.Conv2d`: 2D Convolution Layer\n",
    "\n",
    "```\n",
    "nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
    "```\n",
    "\n",
    "| Argument       | Description                                        |\n",
    "|----------------|----------------------------------------------------|\n",
    "| `in_channels`  | Number of input channels (e.g., 1 for grayscale)   |\n",
    "| `out_channels` | Number of output channels (filters)                |\n",
    "| `kernel_size`  | Size of the convolutional kernel (e.g., 3 for 3×3) |\n",
    "| `stride`       | Step size of the convolution                       |\n",
    "| `padding`      | Amount of zero-padding around input image          |\n",
    "\n",
    "The output height `H_out` is calculated as:\n",
    "\n",
    "```\n",
    "H_out = floor((H_in + 2P - D(K - 1) - 1) / S + 1)\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `P`: padding  \n",
    "- `D`: dilation (default = 1)  \n",
    "- `K`: kernel size  \n",
    "- `S`: stride\n",
    "\n",
    "---\n",
    "\n",
    "## 2. F.relu: Activation Function (ReLU)\n",
    "\n",
    "F.relu(x)\n",
    "\n",
    "Formula:\n",
    "\n",
    "ReLU(x) = max(0, x)\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The ReLU function adds non-linearity to the model. Without non-linear functions, no matter how many layers you stack, the entire network behaves like a single linear transformation. This limits the ability to learn complex patterns.\n",
    "\n",
    "- ReLU outputs zero for any input less than or equal to zero, and outputs the input itself if it is greater than zero.  \n",
    "  In other words, negative values are cut off to zero, while positive values pass through unchanged.\n",
    "\n",
    "- This simple rule makes ReLU computationally efficient because it only requires a comparison and no complex math like exponentials.\n",
    "\n",
    "- Compared to older activation functions like sigmoid or tanh, ReLU helps reduce the vanishing gradient problem, making it easier for deep networks to learn.\n",
    "\n",
    "Example:\n",
    "\n",
    "If the input to ReLU is -3, the output is 0.  \n",
    "If the input is 3, the output is 3.\n",
    "\n",
    "This \"cutting off\" of negative values allows neural networks to model complex data while maintaining efficient training.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 3. `nn.MaxPool2d`: Max Pooling Layer\n",
    "\n",
    "```\n",
    "nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "```\n",
    "\n",
    "- Reduces spatial dimensions (downsampling)  \n",
    "- Provides translation invariance  \n",
    "- Helps reduce overfitting  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. `view()`: Flattening Tensors\n",
    "\n",
    "```\n",
    "x = x.view(-1, 32 * 7 * 7)\n",
    "```\n",
    "\n",
    "- Flattens a 4D tensor into 2D for input into a fully connected layer  \n",
    "- `-1` automatically infers the batch size  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. `nn.Linear`: Fully Connected Layer\n",
    "\n",
    "```\n",
    "nn.Linear(in_features, out_features)\n",
    "```\n",
    "\n",
    "- Connects all input features to output neurons  \n",
    "- Often used as the final classification layer  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. `nn.CrossEntropyLoss`: Loss Function\n",
    "\n",
    "```\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "```\n",
    "\n",
    "This function combines **LogSoftmax** and **Negative Log Likelihood Loss**.\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "```\n",
    "L(x, y) = -log( exp(x[y]) / sum_j exp(x[j]) )\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `x`: raw logits from the model  \n",
    "- `y`: true class index  \n",
    "\n",
    "---\n",
    "\n",
    "## 7. Backpropagation Functions\n",
    "\n",
    "```\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "- `zero_grad()` clears old gradients  \n",
    "- `backward()` computes new gradients  \n",
    "- `step()` updates the model parameters  \n",
    "\n",
    "---\n",
    "\n",
    "## 8. Loading the MNIST Dataset\n",
    "\n",
    "```\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "```\n",
    "\n",
    "- Downloads the MNIST dataset  \n",
    "- Each image is 28×28 grayscale  \n",
    "- `ToTensor()` converts PIL images to PyTorch tensors  \n",
    "\n",
    "---\n",
    "\n",
    "## 9. Full Example: Basic CNN in PyTorch\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a simple CNN\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 28x28 -> 14x14\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 14x14 -> 7x7\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Data loading\n",
    "transform = transforms.ToTensor()\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = BasicCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1):\n",
    "    for images, labels in trainloader:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}], Loss: {loss.item():.4f}\")\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262eb6b4",
   "metadata": {},
   "source": [
    "## References and Further Reading\n",
    "\n",
    "- Andrew Ng, *Machine Learning*, Coursera (Stanford University)  \n",
    "  [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)\n",
    "\n",
    "- DeepLearning.AI, *Supervised Machine Learning: Regression and Classification* (Coursera)  \n",
    "  [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)\n",
    "\n",
    "- Kaggle, *Intro to Machine Learning Micro-course*  \n",
    "  [https://www.kaggle.com/learn/intro-to-machine-learning](https://www.kaggle.com/learn/intro-to-machine-learning)\n",
    "\n",
    "- scikit-learn Documentation, *Supervised Learning*  \n",
    "  [https://scikit-learn.org/stable/supervised_learning.html](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "\n",
    "- Stanford University, *CS231n: Convolutional Neural Networks for Visual Recognition*  \n",
    "  [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
